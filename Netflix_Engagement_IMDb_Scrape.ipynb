{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mgTDThPre1MA",
        "qgt_B7NAPUwz",
        "r2cgXVr9e5Cb",
        "thsEgVKzKUW1",
        "wk6g_fX-LcBD",
        "5UFVh9lxkbrB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning"
      ],
      "metadata": {
        "id": "mgTDThPre1MA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-eEFZt09heb"
      },
      "outputs": [],
      "source": [
        "#load in necessary packages\n",
        "!pip install git+https://github.com/cinemagoer/cinemagoer\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import statistics\n",
        "import time\n",
        "import traceback\n",
        "import sys\n",
        "import datetime\n",
        "import pytz\n",
        "import pandas_gbq\n",
        "\n",
        "#Cinemagoer needs to be capitalized on import\n",
        "import imdb\n",
        "from imdb import Cinemagoer as cg, IMDbError\n",
        "from imdb.helpers import sortedEpisodes\n",
        "\n",
        "#creating instance of Cinemagoer\n",
        "ia = imdb.Cinemagoer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load in data\n",
        "path = 'drive/MyDrive/Data Sci/NFLX - What We Watched/'\n",
        "os.listdir(path)\n",
        "\n",
        "nflx = pd.read_csv(path+'What_We_Watched_A_Netflix_Engagement_Report_2023Jan-Jun.csv', header=4)"
      ],
      "metadata": {
        "id": "pxd0lrDO_oG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning"
      ],
      "metadata": {
        "id": "qgt_B7NAPUwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rename columns for readability\n",
        "nflx = nflx.rename(columns={'Available Globally?': 'avail_globally', 'Release Date': 'release_date', 'Effective Release Date': 'eff_release_date', 'Hours Viewed': 'hours_viewed'})"
      ],
      "metadata": {
        "id": "xK_W8HUxBiG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert columns into datetime\n",
        "nflx['release_date'] = pd.to_datetime(nflx['release_date'])\n",
        "nflx['eff_release_date'] = pd.to_datetime(nflx['eff_release_date'])\n",
        "\n",
        "#convert hours viewed to integer\n",
        "nflx['hours_viewed'] = pd.to_numeric(nflx['hours_viewed'].astype(str).str.replace(',', ''))"
      ],
      "metadata": {
        "id": "xV6sgZKcAUD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating columns for IMDB search\n",
        "nflx['movieID'] = pd.NA\n",
        "nflx['imdb_title'] = pd.NA"
      ],
      "metadata": {
        "id": "pyYuyf3aF97y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating columns that identify the title of the show and the season seperately\n",
        "nflx['true_title'] = nflx['Title'].str.extract(r'^(.*?)(: Season|: Limited Series|: Part|: Chapter|: Book|: Volume|: Series (\\d+))')[0].str.strip()\n",
        "nflx['Season/Series/Part'] = nflx['Title'].str.extract(r'(: Season (\\d+)|: Part (\\d+)|: Chapter (\\d+)|: Book(\\d+)|: Series (\\d+)|: Volume (\\d+))').bfill(axis=1).iloc[:, 1].fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "gZd--v4-lTdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMDb ID Scraping"
      ],
      "metadata": {
        "id": "r2cgXVr9e5Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#top 500 titles (out of 18,000) account for approx. 43% of all hours viewed\n",
        "#93.5 billion hours viewed in total\n",
        "#top 500 is responsible for just under 40b hours viewed\n",
        "#top 715 is responsible for just about 50% of hours\n",
        "#top 2175 is responsible for 75% of hours\n",
        "a = nflx['hours_viewed'].iloc[0:500].sum()\n",
        "b = nflx['hours_viewed'].iloc[:].sum()\n",
        "(a/b)*100"
      ],
      "metadata": {
        "id": "iEsqHUHakC6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8fd5a2-0e36-403e-df2a-92be7e9e0f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.88771518331778"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain the IMDb id for each title\n",
        "\n",
        "#load in top 500 if it hasn't already been scraped\n",
        "try:\n",
        "    nflx_top_500 = pd.read_csv(path+'netflix-top-500.csv')\n",
        "except FileNotFoundError:\n",
        "    nflx_top_500 = pd.DataFrame()\n",
        "\n",
        "if nflx_top_500.empty:\n",
        "\n",
        "  #gathering IMDb IDs (& titles, according to IMDb) for top 100 titles\n",
        "  nflx_top_500 = nflx[['Title', 'avail_globally', 'release_date', 'true_title',\t'Season/Series/Part', 'movieID',\t'imdb_title']].iloc[0:500]\n",
        "\n",
        "  #setting the titles and IDs as variables for the loops\n",
        "  df = nflx_top_500\n",
        "  titles = df['true_title']\n",
        "  IDs = df['movieID']\n",
        "\n",
        "  #find the IMDb id for each title\n",
        "  for title in titles:\n",
        "    try:\n",
        "      digits = ia.search_movie(title)[0].movieID\n",
        "    except IndexError:\n",
        "      #create a null if IMDb record can't be located\n",
        "      digits = pd.NA\n",
        "    #save the IMDb id\n",
        "    df.loc[df['true_title'] == title, 'movieID'] = digits\n",
        "\n",
        "  #find the title in IMDb to check for mismatches\n",
        "  for ID in IDs:\n",
        "    try:\n",
        "      cleaned_ID = ID.lstrip('0')  # Remove leading zeros from IMDb id\n",
        "    except AttributeError:\n",
        "      cleaned_ID = pd.NA\n",
        "\n",
        "    try:\n",
        "        example = ia.get_movie(cleaned_ID)['title']\n",
        "    except (TypeError, IMDbDataAccessError):\n",
        "        example = pd.NA\n",
        "\n",
        "    #save the title as according to IMDb\n",
        "    if pd.notna(example):\n",
        "        df.loc[df['movieID'] == ID, 'imdb_title'] = example\n",
        "    else:\n",
        "        df.loc[df['movieID'] == ID, 'imdb_title'] = pd.NA\n",
        "\n",
        "  #check mismatches of titles to determine if Cinemagoer has scraped the wrong title\n",
        "  df.loc[df['true_title'] != df['imdb_title'], ['Title', 'movieID', 'imdb_title', 'true_title']]"
      ],
      "metadata": {
        "id": "Ch8fCVQle7OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#manually filling titles with missing IDs\n",
        "df.loc[df['true_title'].str.contains('Demon Slayer'), 'movieID'] = 9335498\n",
        "df.loc[df['true_title'].str.contains('Demon Slayer: Kimetsu no Yaiba: Tanjiro Kamado'), 'Season/Series/Part'] = 1\n",
        "\n",
        "#Hunger // คนหิว เกมกระหาย = 22695402\n",
        "df.loc[df['true_title'].str.contains('Hunger // คนหิว เกมกระหาย'), 'movieID'] = 22695402\n",
        "\n",
        "#All Quiet on the Western Front // Im Westen... is 1016150\n",
        "df.loc[df['true_title'].str.contains('All Quiet on the Western Front //'), 'movieID'] = 1016150\n",
        "\n",
        "#ONE PIECE: East Blue is 11757066\n",
        "df.loc[df['true_title'].str.contains('ONE PIECE: East Blue'), 'movieID'] = 11757066\n",
        "\n",
        "#Boys Over Flowers: Volume 1 is 1370334\n",
        "df.loc[df['true_title'].str.contains('Boys Over Flowers'), 'movieID'] = 1370334\n",
        "df.loc[df['true_title'].str.contains('Boys Over Flowers'), 'Season/Series/Part'] = 1\n",
        "\n",
        "#Through My Window 2: Across the Sea is 21245882\n",
        "df.loc[df['true_title'].str.contains('Through My Window 2: Across the Sea'), 'movieID'] = 21245882\n",
        "\n",
        "#Unlocked // 스마트폰을 떨어뜨렸을 뿐인데 is 26160190\n",
        "df.loc[df['true_title'].str.contains('Unlocked // 스마트폰을 떨어뜨렸을 뿐인데'), 'movieID'] = 26160190\n",
        "\n",
        "#Mother's Day // Dzień Matki is 19724192\n",
        "df.loc[df['true_title'].str.contains(\"Mother's Day // Dzień Matki\"), 'movieID'] = 19724192\n",
        "\n",
        "#Rebelde Way (2002): Temporada 1 is 0328789 (and is Season 1)\n",
        "df.loc[df['true_title'].str.contains('Rebelde Way'), 'Season/Series/Part'] = 1"
      ],
      "metadata": {
        "id": "TcpvTm8rw04q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grabbing titles for projects that previously had missing IDs\n",
        "IDs = df.loc[df['imdb_title'].isna(), 'movieID']\n",
        "\n",
        "for ID in IDs:\n",
        "    try:\n",
        "      cleaned_ID = ID.lstrip('0')  # Remove leading zeros\n",
        "    except AttributeError:\n",
        "        cleaned_ID = pd.NA\n",
        "\n",
        "    try:\n",
        "        example = ia.get_movie(cleaned_ID)['title']\n",
        "    except (TypeError, IMDbDataAccessError):\n",
        "        example = pd.NA\n",
        "\n",
        "    if pd.notna(example):\n",
        "        df.loc[df['movieID'] == ID, 'imdb_title'] = example\n",
        "    else:\n",
        "        df.loc[df['movieID'] == ID, 'imdb_title'] = pd.NA"
      ],
      "metadata": {
        "id": "pjY5jDi4-EcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #check mismatches of titles to determine if Cinemagoer has scraped the wrong title\n",
        "  df.loc[df['true_title'] != df['imdb_title'], ['Title', 'movieID', 'imdb_title', 'true_title']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "aBXvB-SeES1X",
        "outputId": "45d30585-6ccc-4162-fc10-416aa7ee8c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Title   movieID  \\\n",
              "17                                      BEEF: Season 1  14403178   \n",
              "22                                        Extraction 2  12263384   \n",
              "24      Doctor Cha: Limited Series // 닥터 차정숙: 리미티드 시리즈  27075857   \n",
              "34          Pablo Escobar, el patrón del mal: Season 1   2187850   \n",
              "44                                   Mr. Queen // 철인왕후  13400006   \n",
              "..                                                 ...       ...   \n",
              "476                         Shameless (U.S.): Season 4   1586680   \n",
              "480                     The Mitchells vs. The Machines   7979580   \n",
              "482  All For Love: Season 1 // Amar y vivir: Tempor...  10347886   \n",
              "489  Thicker Than Water: Season 1 // Jusqu'ici tout...  27124268   \n",
              "491  Daughter From Another Mother: Season 3 // Madr...  11937732   \n",
              "\n",
              "                           imdb_title                        true_title  \n",
              "17                               Beef                              BEEF  \n",
              "22                      Extraction II                      Extraction 2  \n",
              "24               Doctor Cha Jeong Suk                        Doctor Cha  \n",
              "34   Pablo Escobar: El Patrón del Mal  Pablo Escobar, el patrón del mal  \n",
              "44                          Mr. Queen                 Mr. Queen // 철인왕후  \n",
              "..                                ...                               ...  \n",
              "476                         Shameless                  Shameless (U.S.)  \n",
              "480     The Mitchells vs the Machines    The Mitchells vs. The Machines  \n",
              "482                      All for Love               All For Love (2020)  \n",
              "489                Thicker Than Water         Thicker Than Water (2023)  \n",
              "491      Daughter from Another Mother      Daughter From Another Mother  \n",
              "\n",
              "[91 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e016288e-b81c-4780-af26-ce8886c41691\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>movieID</th>\n",
              "      <th>imdb_title</th>\n",
              "      <th>true_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>BEEF: Season 1</td>\n",
              "      <td>14403178</td>\n",
              "      <td>Beef</td>\n",
              "      <td>BEEF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Extraction 2</td>\n",
              "      <td>12263384</td>\n",
              "      <td>Extraction II</td>\n",
              "      <td>Extraction 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Doctor Cha: Limited Series // 닥터 차정숙: 리미티드 시리즈</td>\n",
              "      <td>27075857</td>\n",
              "      <td>Doctor Cha Jeong Suk</td>\n",
              "      <td>Doctor Cha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Pablo Escobar, el patrón del mal: Season 1</td>\n",
              "      <td>2187850</td>\n",
              "      <td>Pablo Escobar: El Patrón del Mal</td>\n",
              "      <td>Pablo Escobar, el patrón del mal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Mr. Queen // 철인왕후</td>\n",
              "      <td>13400006</td>\n",
              "      <td>Mr. Queen</td>\n",
              "      <td>Mr. Queen // 철인왕후</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>Shameless (U.S.): Season 4</td>\n",
              "      <td>1586680</td>\n",
              "      <td>Shameless</td>\n",
              "      <td>Shameless (U.S.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>The Mitchells vs. The Machines</td>\n",
              "      <td>7979580</td>\n",
              "      <td>The Mitchells vs the Machines</td>\n",
              "      <td>The Mitchells vs. The Machines</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>All For Love: Season 1 // Amar y vivir: Tempor...</td>\n",
              "      <td>10347886</td>\n",
              "      <td>All for Love</td>\n",
              "      <td>All For Love (2020)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>Thicker Than Water: Season 1 // Jusqu'ici tout...</td>\n",
              "      <td>27124268</td>\n",
              "      <td>Thicker Than Water</td>\n",
              "      <td>Thicker Than Water (2023)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>Daughter From Another Mother: Season 3 // Madr...</td>\n",
              "      <td>11937732</td>\n",
              "      <td>Daughter from Another Mother</td>\n",
              "      <td>Daughter From Another Mother</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e016288e-b81c-4780-af26-ce8886c41691')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e016288e-b81c-4780-af26-ce8886c41691 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e016288e-b81c-4780-af26-ce8886c41691');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4b80990-8c16-47a5-9729-500eeb748a22\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4b80990-8c16-47a5-9729-500eeb748a22')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4b80990-8c16-47a5-9729-500eeb748a22 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#correcting titles that Cinemagoer has misidentified\n",
        "\n",
        "df.loc[df['true_title'] == 'Til Money Do Us Part', 'true_title'] = 'Until Money Do Us Part'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Woman of the Dead'), 'true_title'] = 'Woman of the Dead (2022)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Hajime no Ippo'), 'movieID'] = 481256\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Sky High: The Series'), 'true_title'] = 'Sky High (2023)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Paw Patrol: The Movie'), 'true_title'] = 'Paw Patrol: The Movie (2021)'\n",
        "\n",
        "df.loc[df['true_title'] == ('Trolls'), 'true_title'] = 'Trolls (2016)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('The Queen of Flow'), 'true_title'] = 'The Queen of Flow (2021) (2018)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Masha and the Bear'), 'true_title'] = 'Masha and the Bear (2007)'\n",
        "\n",
        "df.loc[df['true_title'] == 'The Nurse', 'true_title'] = 'The Nurse (2023)'\n",
        "\n",
        "df.loc[df['true_title'] == 'Home', 'true_title'] = 'Home (2015)'\n",
        "\n",
        "df.loc[df['true_title'] == ('Faraway'), 'movieID'] = 18747542\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Newly Rich, Newly Poor'), 'true_title'] = 'Newly Rich, Newly Poor (2007)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('JUNG_E'), 'true_title'] = 'JUNG_E'\n",
        "\n",
        "df.loc[df['true_title'] == 'Puss in Boots', 'true_title'] = 'Puss in Boots (2011)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('In Love All Over Again'), 'true_title'] = 'In Love All Over Again (2023)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Pokémon The Series: Indigo League'), 'true_title'] = 'Pokémon (1997)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Demon Slayer: Kimetsu no Yaiba: Swordsmith Village Arc'), 'Season/Series/Part'] = 4\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Pokémon Journeys: The Series'), 'true_title'] = 'Pokémon Journeys'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Sanctuary: Season 1'), 'true_title'] = 'Sanctuary (2023)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('As Aventuras de Poliana'), 'true_title'] = 'As Aventuras de Poliana (2018)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('All For Love'), 'true_title'] = 'All For Love (2020)'\n",
        "\n",
        "df.loc[df['true_title'].str.contains('Thicker Than Water'), 'true_title'] = 'Thicker Than Water (2023)'"
      ],
      "metadata": {
        "id": "xEYk2Fxe_810"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating nulls for titles without IMDb pages\n",
        "mask = df['true_title'].notna() & df['true_title'].str.contains(\"Blippi's Adventures\", na=False)\n",
        "df.loc[mask, ['movieID', 'imdb_title']] = pd.NA\n",
        "\n",
        "mask = df['true_title'].notna() & df['true_title'].str.contains('Little Angel', na=False)\n",
        "df.loc[mask, ['movieID', 'imdb_title']] = pd.NA"
      ],
      "metadata": {
        "id": "uWFBIqfQquLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rerunning the adjusted titles through the IMDb id scraper\n",
        "adjusted_titles = [\n",
        "    'Until Money Do Us Part',\n",
        "    'Woman of the Dead (2022)',\n",
        "    'Sky High (2023)',\n",
        "    'Paw Patrol: The Movie (2021)',\n",
        "    'Trolls (2016)',\n",
        "    'The Queen of Flow (2021) (2018)',\n",
        "    'Masha and the Bear (2007)',\n",
        "    'The Nurse (2023)',\n",
        "    'Home (2015)',\n",
        "    'Newly Rich, Newly Poor (2007)',\n",
        "    'JUNG_E',\n",
        "    'Puss in Boots (2011)',\n",
        "    'In Love All Over Again (2023)',\n",
        "    'Pokémon (1997)',\n",
        "    'Pokémon Journeys',\n",
        "    'Sanctuary (2023)',\n",
        "    'As Aventuras de Poliana (2018)',\n",
        "    'All For Love (2020)',\n",
        "    'Thicker Than Water (2023)'\n",
        "]\n",
        "\n",
        "for title in adjusted_titles:\n",
        "    try:\n",
        "        digits = ia.search_movie(title)[0].movieID\n",
        "    except IndexError:\n",
        "        digits = pd.NA\n",
        "    df.loc[df['true_title'] == title, 'movieID'] = digits\n",
        "\n",
        "#excluding rows with nulls and selecting rows where the title from data and IMDb title are mismatched\n",
        "valid_rows = df.dropna(subset=['true_title', 'imdb_title'])\n",
        "for index, row in valid_rows[valid_rows['true_title'] != valid_rows['imdb_title']].iterrows():\n",
        "    movieID = row['movieID']\n",
        "\n",
        "    try:\n",
        "        cleaned_ID = movieID.lstrip('0')  # Remove leading zeros\n",
        "    except AttributeError:\n",
        "        cleaned_ID = pd.NA\n",
        "\n",
        "    try:\n",
        "        example = ia.get_movie(cleaned_ID)['title']\n",
        "    except (TypeError, IMDbDataAccessError):\n",
        "        example = pd.NA\n",
        "\n",
        "    if pd.notna(example):\n",
        "        df.at[index, 'imdb_title'] = example\n",
        "    else:\n",
        "        df.at[index, 'imdb_title'] = pd.NA"
      ],
      "metadata": {
        "id": "hmzv36DNoKP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting rows with a missing IMDb title and excluding Blippi's Adventures & Little Angel\n",
        "valid_rows = df.loc[df['imdb_title'].isna() & ~df['true_title'].str.contains(\"Blippi's Adventures|Little Angel\", case=False, na=False)]\n",
        "IDs = valid_rows['movieID']\n",
        "\n",
        "for index, ID in IDs.iteritems():\n",
        "    try:\n",
        "        cleaned_ID = str(int(ID)).lstrip('0')  # Convert to integer, remove leading zeros\n",
        "    except (AttributeError):\n",
        "        cleaned_ID = None\n",
        "\n",
        "    try:\n",
        "        example = ia.get_movie(cleaned_ID)['title']\n",
        "    except (TypeError, IMDbDataAccessError):\n",
        "        example = None\n",
        "\n",
        "    if pd.notna(example):\n",
        "        df.at[index, 'imdb_title'] = example\n",
        "    else:\n",
        "        df.at[index, 'imdb_title'] = pd.NA"
      ],
      "metadata": {
        "id": "6YzoWqO1L9c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge the new dataset with netflix top 500\n",
        "merged_df = pd.merge(nflx, df, on='Title', how='inner', suffixes=('_nflx', '_df'))"
      ],
      "metadata": {
        "id": "L_SZ9LRsS-wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['movieID_nflx', 'imdb_title_nflx', 'true_title_nflx', 'Season/Series/Part_nflx', 'avail_globally_df', 'release_date_df']\n",
        "\n",
        "# Drop the duplicated columns\n",
        "merged_df.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "POXMprtfTrCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_rename = {\n",
        "    'avail_globally_nflx': 'avail_globally',\n",
        "    'release_date_nflx': 'release_date',\n",
        "    'true_title_df': 'true_title',\n",
        "    'Season/Series/Part_df': 'Season_Series_Part',\n",
        "    'movieID_df': 'movieID',\n",
        "    'imdb_title_df': 'imdb_title'\n",
        "}\n",
        "\n",
        "# Rename columns for readability\n",
        "merged_df.rename(columns=columns_to_rename, inplace=True)"
      ],
      "metadata": {
        "id": "3s54rXNbUGJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save merged data as csv\n",
        "merged_df.to_csv('nflx-top-500.csv')"
      ],
      "metadata": {
        "id": "oVbLZMxJUhQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMDb 'Kind' Scrape"
      ],
      "metadata": {
        "id": "thsEgVKzKUW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set temporary dataframe\n",
        "xdf = nflx_top_500[['Title', 'Season_Series_Part', 'movieID']]\n",
        "\n",
        "#drop titles with missing IDs\n",
        "xdf = xdf.dropna(subset=['movieID'])\n",
        "\n",
        "#convert IDs to integers\n",
        "xdf['movieID'] = xdf['movieID'].astype(int)"
      ],
      "metadata": {
        "id": "j6GUd6_uKhf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtaining all 'kinds' of titles for filtering\n",
        "\n",
        "key = 'kind'\n",
        "\n",
        "IDs = xdf.loc[xdf['kind'].isna(), 'movieID']\n",
        "\n",
        "error_IDs = []\n",
        "\n",
        "error_IDs_2 = []\n",
        "\n",
        "for ID in IDs:\n",
        "    try:\n",
        "      title = ia.get_movie(ID)\n",
        "\n",
        "      #create a boolean mask based on movieID\n",
        "      mask = xdf['movieID'] == ID\n",
        "\n",
        "      #save the 'kind' of title to the dataframe for each row\n",
        "      value = title[key]\n",
        "      xdf.loc[mask, key] = value\n",
        "\n",
        "    except IMDbError:\n",
        "      #save IDs with errors in list for rechecking\n",
        "      error_IDs.append(ID)\n",
        "\n",
        "#rerun IDs that got errors in\n",
        "for ID in error_IDs:\n",
        "    try:\n",
        "        title = ia.get_movie(ID)\n",
        "\n",
        "        #create a boolean mask based on movieID\n",
        "        mask = xdf['movieID'] == ID\n",
        "\n",
        "        #save the 'kind' of title to the dataframe for each row\n",
        "        value = title[key]\n",
        "        xdf.loc[mask, key] = value\n",
        "\n",
        "    except IMDbError:\n",
        "        #save IDs with a 2nd error in list for rechecking\n",
        "        error_IDs_2.append(ID)"
      ],
      "metadata": {
        "id": "JyPfqk2cKrV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#retrieve every unique kind of title\n",
        "xdf['kind'].unique()"
      ],
      "metadata": {
        "id": "jXLBhWyZLNdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save title kinds to csv\n",
        "xdf.to_csv('title-kinds.csv')"
      ],
      "metadata": {
        "id": "dwVtv0RtLN3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMDb Primary Scrape"
      ],
      "metadata": {
        "id": "wk6g_fX-LcBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#list important data for scraping\n",
        "main_keys = [\n",
        "    'aspect ratio',\n",
        "    'country codes',\n",
        "    'distributors',\n",
        "    'genres',\n",
        "    'imdbID',\n",
        "    'kind',\n",
        "    'language codes',\n",
        "    'production companies',\n",
        "    'rating',\n",
        "    'runtimes',\n",
        "    'seasons',\n",
        "    'stars',\n",
        "    'year',\n",
        "]\n",
        "\n",
        "\n",
        "#list kinds of TV listed in IMDb for filtering\n",
        "tv_types = [\n",
        "    'tv series', 'tv mini series'\n",
        "]"
      ],
      "metadata": {
        "id": "dd41yohVLem_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create DataFrame for full scrape\n",
        "title_kinds = pd.read_csv(path+'title-kinds.csv')\n",
        "df = title_kinds\n",
        "df = df.rename(columns={'Season_Series_Part': 'Season'})\n",
        "\n",
        "#converting Season to integer\n",
        "df['Season'] = df['Season'].astype(int)\n",
        "\n",
        "#properly numbering mini-series with no 'Season' #\n",
        "df.loc[(df['kind'] == 'tv mini series') & (df['Season'] == 0), 'Season'] = 1\n",
        "\n",
        "#The Lorax is wrong, it should be the 2012 movie, its actual ID is #1482459\n",
        "df.loc[(df['Title'] == \"Dr. Seuss' The Lorax\"), 'movieID'] = '1482459'\n",
        "\n",
        "#initialize columns for keys\n",
        "for key in main_keys:\n",
        "    df[key] = 0\n",
        "\n",
        "#initialize episode count:\n",
        "df['eps_in_season'] = 0\n",
        "\n",
        "#initialize error counter columns\n",
        "error_counters = [\n",
        "    'runtime_key_error',\n",
        "    'runtime_timeout_error',\n",
        "    'rating_key_error',\n",
        "    'rating_timeout_error',\n",
        "    'other_errors',\n",
        "    'general_timeout_error'\n",
        "]\n",
        "\n",
        "for error_counter in error_counters:\n",
        "    df[error_counter] = 0"
      ],
      "metadata": {
        "id": "gmNUoVfwLorO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to simultaneously log messages/errors while presenting them in output\n",
        "def custom_print(message, log_file):\n",
        "    print(message)\n",
        "    print(message, file=log_file)\n",
        "\n",
        "#function to handle exceptions\n",
        "def handle_exception(title, ID, e, log_file):\n",
        "    print(f\"Error: {e} for {title} (ID: {ID})\", file=log_file)\n",
        "    print(f\"Exception details: {repr(e)}\", file=log_file)\n",
        "    traceback.print_exc(file=log_file)\n",
        "    time.sleep(delay_seconds)\n",
        "\n",
        "#function to handle timeouts and notify in output & log simultaneously\n",
        "def handle_timeout_error(title, ID, te, log_file):\n",
        "    custom_print(f\"Timeout Error for {title} (ID: {ID})\", log_file)\n",
        "    print(f\"Exception details: {repr(te)}\", file=log_file)\n",
        "    time.sleep(delay_seconds)"
      ],
      "metadata": {
        "id": "Xcq1BL76MBlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scrape of all necessary IMDb data as identified in main_keys\n",
        "#Uses batch processing and checkpoints to save progress in a csv for every 100 titles processed\n",
        "#prints status and certain errors while simultaneously saving them in a log file\n",
        "\n",
        "max_retries = 2\n",
        "delay_seconds = 5\n",
        "batch_size = 25\n",
        "checkpoint_interval = 100\n",
        "\n",
        "#set path for saving data\n",
        "path2 = 'drive/MyDrive/Data Sci/NFLX - What We Watched/Scrape/'\n",
        "\n",
        "#set variables for loop\n",
        "df_titles = df['Title']\n",
        "IDs = df['movieID']\n",
        "\n",
        "#set the Pacific Timezone\n",
        "pacific = pytz.timezone('America/Los_Angeles')\n",
        "#get the current time in Pacific Time\n",
        "now_pacific = datetime.datetime.now(pacific)\n",
        "#format the timestamp for readability\n",
        "timestamp = now_pacific.strftime(\"%Y_%m_%d_%I_%M%p\")\n",
        "\n",
        "#log all prints and errors for analysis and debugging\n",
        "log_file_path = (path2 + f'output_log_{timestamp}.txt')\n",
        "with open(log_file_path, 'w') as log_file:\n",
        "\n",
        "  batch_counter = 0  #initialize batch counter\n",
        "\n",
        "  for start in range(0, len(df_titles), batch_size):\n",
        "      batch_titles = df_titles[start:start + batch_size]\n",
        "      batch_IDs = IDs[start:start + batch_size]\n",
        "\n",
        "      #track processing\n",
        "      now_pacific = datetime.datetime.now(pacific)\n",
        "      timestamp = now_pacific.strftime(\"%Y_%m_%d_%I_%M%p\")\n",
        "      custom_print(f\"Processing Batch: {start + 1} - {min(start + batch_size, len(df_titles))} at {timestamp}\", log_file)\n",
        "\n",
        "      for ID, df_title in zip(batch_IDs, batch_titles):\n",
        "          #initializing variables in case they are needed in TV episode loop\n",
        "          trt = 0\n",
        "          sum_ratings = 0\n",
        "          ratings_count = 0\n",
        "          _ep_runtime_count = 0\n",
        "          _ep_rating_count = 0\n",
        "\n",
        "          #initializing error counters\n",
        "          other_errors_count = 0\n",
        "          general_timeout_error_count = 0\n",
        "          runtime_key_error = 0\n",
        "          runtime_timeout_error = 0\n",
        "          rating_key_error = 0\n",
        "          rating_timeout_error = 0\n",
        "\n",
        "          #retry loop in case of TimeoutErrors\n",
        "          for retry in range(max_retries):\n",
        "              try:\n",
        "                title = ia.get_movie(ID)\n",
        "\n",
        "                #create a boolean mask based on movieID\n",
        "                mask2 = df['Title'] == df_title\n",
        "\n",
        "                for key in main_keys:\n",
        "                    if key in title:\n",
        "                      value = title[key]\n",
        "\n",
        "                      if isinstance(value, (list, tuple)):\n",
        "                        #if iterable, concatenate the list into a single string and update DataFrame\n",
        "                        concatenated_value = ', '.join(map(str, value))\n",
        "                        df.loc[mask2, key] = concatenated_value\n",
        "                      else:\n",
        "                        #if not iterable, update dataframe with the single value\n",
        "                        df.loc[mask2, key] = value\n",
        "\n",
        "                #obtaining individual episode data for each season of TV\n",
        "                if not df.loc[mask2 & (df['kind'].isin(tv_types))].empty:\n",
        "\n",
        "                  #update the title object with the episodes infoset\n",
        "                  ia.update(title, 'episodes')\n",
        "\n",
        "                  #obtain array of episodes in season\n",
        "                  eps = sortedEpisodes(title, season=int(df.loc[mask2, 'Season'].iloc[0]))\n",
        "                  print(f\"Number of episodes: {len(eps)}\")\n",
        "                  #save number of episodes\n",
        "                  eps_count = int(len(eps))\n",
        "                  df.loc[mask2, 'eps_in_season'] = eps_count\n",
        "\n",
        "                  #getting runtimes for each episode to calc total runtime\n",
        "                  for ep in eps:\n",
        "                    _ep = ia.get_movie(ep.movieID)\n",
        "                    try:\n",
        "                      mins = int(_ep.get('runtimes', [0])[0])\n",
        "                      trt += mins\n",
        "                      _ep_runtime_count += 1\n",
        "                    except KeyError as k:\n",
        "                      #log and count key errors\n",
        "                      handle_exception(df_title, ID, k, log_file)\n",
        "                      runtime_key_error += 1\n",
        "                    except TimeoutError as te:\n",
        "                      #log and count timeout errors\n",
        "                      handle_timeout_error(df_title, ID, te, log_file)\n",
        "                      runtime_timeout_error += 1\n",
        "\n",
        "                  df.loc[mask2, 'runtime_key_error'] = runtime_key_error\n",
        "                  df.loc[mask2, 'runtime_timeout_error'] = runtime_timeout_error\n",
        "\n",
        "                  #only replacing the 'runtime' column if each episode has a valid 'runtime' value. otherwise leave the runtime initially retrieved by the movieID\n",
        "                  if (df.loc[mask2, 'runtime_key_error'].iloc[0] == 0) & (_ep_runtime_count == eps_count) & (_ep_runtime_count != 0):\n",
        "                    df.loc[mask2, 'runtimes'] = trt\n",
        "                  print(f\"{df_title} has TRT of {df.loc[mask2, 'runtimes'].iloc[0]}\", file=log_file)\n",
        "                  else:\n",
        "                      # Handle the case where no individual episode runtimes were available. leave the rating first retrieved by the movieID\n",
        "                      print(f\"{df_title} has incomplete individual episode runtimes\", file=log_file)\n",
        "\n",
        "                  #getting ratings for each episode to calc average\n",
        "                  for ep in eps:\n",
        "                    _ep = ia.get_movie(ep.movieID)\n",
        "                    try:\n",
        "                      ep_rating = float(_ep.get('rating', 0))\n",
        "                      sum_ratings += ep_rating\n",
        "                      ratings_count += 1\n",
        "                    except KeyError as k:\n",
        "                      #log and count key errors\n",
        "                      handle_exception(df_title, ID, k, log_file)\n",
        "                      rating_key_error += 1\n",
        "                    except TimeoutError as te:\n",
        "                      #log and count timeout errors\n",
        "                      handle_timeout_error(df_title, ID, te, log_file)\n",
        "                      rating_timeout_error += 1\n",
        "\n",
        "                  df.loc[mask2, 'rating_key_error'] = rating_key_error\n",
        "                  df.loc[mask2, 'rating_timeout_error'] = rating_timeout_error\n",
        "\n",
        "                  #only replacing the 'rating' column if each episode has a valid 'rating' value. otherwise leave the rating initially retrieved by the movieID\n",
        "                  if (df.loc[mask2, 'rating_key_error'].iloc[0] == 0) & (ratings_count == eps_count) & (_ep_rating_count != 0):\n",
        "                      average_rating = sum_ratings / ratings_count\n",
        "                      df.loc[mask2, 'rating'] = average_rating\n",
        "                      print(f\"{df_title} has rating of {df.loc[mask2, 'rating'].iloc[0]}\", file=log_file)\n",
        "                  else:\n",
        "                      # Handle the case where no individual episode ratings were available. leave the rating first retrieved by the movieID\n",
        "                      print(f\"{df_title} has incomplete individual episode ratings\", file=log_file)\n",
        "\n",
        "                break  #break the retry loop if successful\n",
        "\n",
        "              #log and count any other unexpected errors\n",
        "              except Exception as e:\n",
        "                handle_exception(df_title, ID, e, log_file)\n",
        "                other_errors_count += 1\n",
        "              except TimeoutError as te:\n",
        "                handle_timeout_error(df_title, ID, te, log_file)\n",
        "                general_timeout_error_count += 1\n",
        "\n",
        "          df.loc[mask2, 'other_errors'] = other_errors_count\n",
        "          df.loc[mask2, 'general_timeout_error'] = general_timeout_error_count\n",
        "\n",
        "          #increase batch counter for every successful loop\n",
        "          batch_counter += 1\n",
        "\n",
        "          #save data every 100 titles with a timestamped title\n",
        "          if batch_counter % checkpoint_interval == 0:\n",
        "              now_pacific = datetime.datetime.now(pacific)\n",
        "              timestamp = now_pacific.strftime(\"%Y_%m_%d_%I_%M%p\")\n",
        "              checkpoint_number = batch_counter // checkpoint_interval\n",
        "              checkpoint_filename = f'scrape_checkpoint_{checkpoint_number}_{timestamp}.csv'\n",
        "              df.to_csv(path2 + checkpoint_filename, index=False)\n",
        "              custom_print(f\"Checkpoint {checkpoint_number} reached at {timestamp}\", log_file)\n",
        "\n",
        "#save all data if end of dataframe is successfully reached\n",
        "timestamp_final = now_pacific.strftime(\"%Y_%m_%d_%I_%M%p\")\n",
        "df.to_csv(path2 + f'scrape-final_{timestamp_final}.csv', index=False)"
      ],
      "metadata": {
        "id": "NMT0jPe7MCYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing to BigQuery"
      ],
      "metadata": {
        "id": "5UFVh9lxkbrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path2 = 'drive/MyDrive/Data Sci/NFLX - What We Watched/Send to Big Query/'\n",
        "os.listdir(path2)\n",
        "\n",
        "#setting up BigQuery project ID and dataset for export\n",
        "project = 'netflix-what-we-watched'\n",
        "dataset = 'top_500'\n",
        "\n",
        "#importing each dataset from Google Sheets\n",
        "sheets = ['hours_viewed',\n",
        "          'title_kinds',\n",
        "          'imdb_data_full'\n",
        "]\n",
        "\n",
        "for sheet in sheets:\n",
        "  table = pd.read_csv(path2+f'{sheet}.csv', header=1)\n",
        "\n",
        "  # send each dataframe to the corresponding table in BigQuery\n",
        "  pandas_gbq.to_gbq(df, f'{dataset}.{table}', project_id=project)"
      ],
      "metadata": {
        "id": "q9KukA1pPfvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}